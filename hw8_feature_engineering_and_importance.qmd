---
title: "Homework #8: Feature Engineering and Importance" 
author: "Mark"
---

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```

# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
dir_data = '~/School/Data Mining/Data' # data directory
library(tidyverse) # functions for data manipulation 
library(ggplot2)
library(randomForest)
library(mice)
library(Metrics)
```

# Problem 1: Permutation Feature Importance

Vanderbilt Biostats has collected data on Titanic survivors (https://hbiostat.org/data/). I have done some simple processing and split into a training and test sets.

-   [titanic_train.csv](%60r%20file.path(dir_data,%20%22titanic_train.csv%22)%60)
-   [titanic_test.csv](%60r%20file.path(dir_data,%20%22titanic_test.csv%22)%60)

We are going to use this data to investigate feature importance. Use `Class`, `Sex`, `Age`, `Fare`, `sibsp` (number of siblings or spouse on board), `parch` (number of parents or children on board), and `Joined` (city where passenger boarded) for the predictor variables (features) and `Survived` as the outcome variable.

## a. Method 1: Built-in importance scores

Fit a tree ensemble model (e.g., Random Forest, boosted tree) on the training data. You are free to use any method to select the tuning parameters.

Report the built-in feature importance scores and produce a barplot with feature on the x-axis and importance on the y-axis.

```{r}
train_data = read.csv('~/School/Data Mining/Data/titanic_train.csv')
test_data = read.csv('~/School/Data Mining/Data/titanic_test.csv')
train_data$Sex = as.factor(train_data$Sex)
train_data$Joined = as.factor(train_data$Joined)
train_data$Survived = as.factor(train_data$Survived)
train_data = train_data[, c("Survived", "Class", "Sex", "Age", "Fare", "sibsp", "parch", "Joined", "Occupation")]

train_data$Occupation[is.na(train_data$Occupation)]="Unemployed"
test_data$Occupation[is.na(test_data$Occupation)]="Unemployed"


imputed_data = mice(data.frame(train_data)) # m = number of imputations

completed_data = complete(imputed_data)

train_data = as.data.frame(completed_data)

imputed_data2 = mice(test_data) # m = number of imputations

completed_data2 = complete(imputed_data2)

test_data = as.data.frame(completed_data2)

colSums(is.na(train_data))


set.seed(40)  #
rf_model = randomForest(Survived ~ ., data = train_data, importance = TRUE)

importance = as.data.frame(rf_model$importance[, 'MeanDecreaseGini'])
importance$Feature = rownames(importance)


ggplot(importance, aes(x = Feature, y = rf_model$importance[, "MeanDecreaseGini"])) +
  geom_bar(stat = "identity", fill = "steelblue") 

```

## b. Performance

Report the performance of the model fit from (a.) on the test data. Use the log-loss (where $M$ is the size of the test data): $$ 
\text{log-loss}(\hat{p}) = - \frac{1}{M} \sum_{i=1}^m [y_i \log \, \hat{p}_i + (1 - y_i) \log \, (1 - \hat{p}_i)]
$$

```{r}
test_data$Sex = as.factor(test_data$Sex)
test_data$Joined = as.factor(test_data$Joined)
test_data$Survived = as.factor(test_data$Survived)
X_test = test_data[, c("Class", "Sex", "Age", "Fare", "sibsp", "parch", "Joined", "Occupation")]


predicted_probs = predict(rf_model, X_test, type = "prob")[,2]

actual_numeric = as.numeric(as.character(test_data$Survived))

log_loss_value = logLoss(actual_numeric, predicted_probs)
print(log_loss_value)

```

## c. Method 2: Permute *after* fitting

Use the fitted model from question (a.) to perform permutation feature importance. Shuffle/permute each variable individually on the *test set* before making predictions. Record the loss. Repeat $M=10$ times and produce a boxplot of the change in loss (change from reported loss from part b.).

```{r}
M=10
baseline_log_loss = logLoss(actual_numeric, predicted_probs)

feature_importances = list()

set.seed(40) 
for (feature in names(test_data[, -which(names(test_data) == "Survived")])) {
  losses = numeric(M)  
  
  for (i in 1:M) {
    permuted_data = test_data
    permuted_data[[feature]] = sample(permuted_data[[feature]])
    
    permuted_probs = predict(rf_model, newdata = permuted_data, type = "prob")[,2]
    
    permuted_log_loss = logLoss(actual_numeric, permuted_probs)
    
    losses[i] = permuted_log_loss - baseline_log_loss
  }
  
  feature_importances[[feature]] = losses
}

importances_df = stack(feature_importances)

ggplot(importances_df, aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Feature", y = "Change in Log-Loss")

```

## d. Method 3: Permute *before* fitting

For this approach, shuffle/permute the *training data* and re-fit the ensemble model. Evaluate the predictions on the (unaltered) test data. Repeat $M=10$ times (for each predictor variable) and produce a boxplot of the change in loss.

```{r}

M = 10  
original_probs = predict(rf_model, newdata = test_data, type = "prob")[,2]
original_log_loss = logLoss(actual_numeric, original_probs)

loss_changes = list()

for (feature in names(train_data[, -which(names(train_data) == "Survived")])) {
  feature_losses = numeric(M)
  
  for (i in 1:M) {
    permuted_train_data = train_data
    permuted_train_data[[feature]] = sample(permuted_train_data[[feature]])
    
    permuted_rf_model = randomForest(Survived ~ ., data = permuted_train_data, importance = TRUE)
    
    test_probs = predict(permuted_rf_model, newdata = test_data, type = "prob")[,2]
    test_log_loss = logLoss(actual_numeric, test_probs)
    
    feature_losses[i] = test_log_loss - original_log_loss
  }
  
  loss_changes[[feature]] = feature_losses
}

loss_changes_df = stack(loss_changes)

ggplot(loss_changes_df, aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Feature", y = "Change in Log-Loss")

```

## e. Understanding

Describe the benefits of each of the three approaches to measure feature importance.

::: {.callout-note title="Solution"}
Feature importance increases the error when information is destroyed and provides global insight into the behavior. You are also able to compare the error difference across different problems. This also does not require retraining the model, and takes into account all interactions.
:::

# Problem 2: Effects of correlated predictors

This problem will illustrate what happens to the importance scores when there are highly associated predictors.

## a. Create an almost duplicate feature

Create a new feature `Sex2` that is 95% the same as `Sex`. Do this by selecting 5% of training ($n=50$) and testing ($n=15$) data and flip the `Sex` value.

```{r}
set.seed(40)  


train_data$Sex2 = train_data$Sex
test_data$Sex2 = test_data$Sex

n_train = nrow(train_data)
n_test = nrow(test_data)

train_flip_indices = sample(1:n_train, size = 0.05 * n_train)
test_flip_indices = sample(1:n_test, size = 0.05 * n_test)

train_data$Sex2[train_flip_indices] = ifelse(train_data$Sex[train_flip_indices] == "male", "female", "male")
test_data$Sex2[test_flip_indices] = ifelse(test_data$Sex[test_flip_indices] == "male", "female", "male")

train_data
test_data
```

## b. Method 1: Built-in importance

Fit the same model as in Problem 1a, but use the new data that includes `Sex2` (i.e., use both `Sex` and `Sex2` in the model). Calculate the built-in feature importance score and produce a barplot.

```{r message=FALSE, warning=FALSE}
train_data$Sex = as.factor(train_data$Sex)
train_data$Sex2 = as.factor(train_data$Sex2)

set.seed(42)  
rf_model = randomForest(Survived ~ ., data = train_data, importance = TRUE)

importance_two = as.data.frame(rf_model$importance[, 'MeanDecreaseGini'])
importance_two$Feature = rownames(importance_two)

ggplot(importance_two, aes(x = Feature, y = rf_model$importance[, "MeanDecreaseGini"])) +
  geom_bar(stat = "identity", fill = "steelblue") 

```

## c. Method 2: Permute *after* fitting

Redo Method 2 (problem 1c) on the new data/model and produce a boxplot of importance scores. The importance score is defined as the difference in loss.

```{r}
original_probs = predict(rf_model, newdata = test_data, type = "prob")[,2]
original_log_loss = logLoss(actual_numeric, original_probs)

set.seed(40)  
M = 10 
feature_changes = list()

for (feature in names(test_data[, -which(names(test_data) == "Survived")])) {
  changes = numeric(M)
  
  for (i in 1:M) {
    permuted_test_data = test_data
    permuted_test_data[[feature]] = sample(permuted_test_data[[feature]])
    
    permuted_probs = predict(rf_model, newdata = permuted_test_data, type = "prob")[,2]
    permuted_log_loss = logLoss(actual_numeric, permuted_probs)
    
    changes[i] = permuted_log_loss - original_log_loss
  }
  
  feature_changes[[feature]] = changes
}

importance_df = stack(feature_changes)

library(ggplot2)
ggplot(importance_df, aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Feature", y = "Change in Log-Loss")


```

## d. Method 3: Permute *before* fitting

Redo Method 3 (problem 1d) on the new data and produce a boxplot of importance scores. The importance score is defined as the difference in loss.

```{r}
original_probs = predict(rf_model, newdata = test_data, type = "prob")[, 2]
original_log_loss = logLoss(actual_numeric, original_probs)

set.seed(40) 
M = 10 
feature_importances = list()

for (feature in names(train_data[, -which(names(train_data) == "Survived")])) {
  differences = numeric(M)
  
  for (i in 1:M) {
    permuted_train_data = train_data
    permuted_train_data[[feature]] = sample(permuted_train_data[[feature]])
    
    permuted_rf_model = randomForest(Survived ~ ., data = permuted_train_data, importance = TRUE)
    
    permuted_probs = predict(permuted_rf_model, newdata = test_data, type = "prob")[, 2]
    permuted_log_loss = logLoss(actual_numeric, permuted_probs)
    
    differences[i] = permuted_log_loss - original_log_loss
  }
  
  feature_importances[[feature]] = differences
}

importance_df = stack(feature_importances)

library(ggplot2)
ggplot(importance_df, aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Feature", y = "Change in Log-Loss")

```

## e. Understanding

Describe how the addition of the almost duplicated predictor impacted the feature importance results.

::: {.callout-note title="Solution"}
It can help determine how important that specific predictor is, does it actually have a large impact on the results or not. Can also help the model be more accurate by increasing the complexity of the model, with changing the data.
:::
