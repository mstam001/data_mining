---
title: "Homework #4: Probability and Classification" 
author: "Mark Stammler"
format: sys6018hw-html
---

::: {style="background-color:yellow; color:red; display: block; border-color: black; padding:1em"}
This is an **independent assignment**. Do not discuss or work with classmates.
:::

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```

# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
dir_data= 'https://mdporter.github.io/SYS6018/data/' # data directory
library(glmnet)    # for glmnet() functions
library(yardstick) # for evaluation metrics
library(tidyverse) # functions for data manipulation  
```

# Crime Linkage

Crime linkage attempts to determine if a set of unsolved crimes share a common offender. *Pairwise* crime linkage is the more simple task of deciding if two crimes share a common offender; it can be considered a binary classification problem. The linkage training data has 8 evidence variables that measure the similarity between a pair of crimes:

-   `spatial` is the spatial distance between the crimes
-   `temporal` is the fractional time (in days) between the crimes
-   `tod` and `dow` are the differences in time of day and day of week between the crimes
-   `LOC`, `POA,` and `MOA` are binary with a 1 corresponding to a match (type of property, point of entry, method of entry)
-   `TIMERANGE` is the time between the earliest and latest possible times the crime could have occurred (because the victim was away from the house during the crime).
-   The response variable indicates if the crimes are linked ($y=1$) or unlinked ($y=0$).

These problems use the [linkage-train](https://mdporter.github.io/DS6030/data/linkage_train.csv) and [linkage-test](https://mdporter.github.io/DS6030/data/linkage_test.csv) datasets (click on links for data).

## Load Crime Linkage Data

```{r }
#Add solution here.

train = '~/School/Data Mining/Data/linkage_train.csv'
test = '~/School/Data Mining/Data/linkage_test.csv'

train = readr::read_csv(train)
test = readr::read_csv(test)
```

# Problem 1: Penalized Regression for Crime Linkage

## a. Fit a penalized *linear regression* model to predict linkage.

Use an elastic net penalty (including lasso and ridge) (your choice).

-   Report the value of $\alpha \in [0, 1]$ used
-   Report the value of $\lambda$ used
-   Report the estimated coefficients

```{r }
library(glmnet)
X = glmnet::makeX(select(train, -y), test)
X.train = X$x
X.test = X$xtest
Y.train = train$y

set.seed(923)  
K = 10           
folds = rep(1:K, length=nrow(X.train)) %>% sample() # make folds

est_rmse <- function(alpha, folds){
  min(cv.glmnet(X.train, Y.train, foldid = folds, alpha=alpha)$cvm) %>% sqrt()
}
alpha_seq = seq(0, 1, by=.05)

RMSE = sapply(alpha_seq, est_rmse, folds=folds)

set.seed(242)
RMSE2 = tibble()
for(i in 1:50){
  folds_new = sample(folds) # shuffle folds
  rmse = tibble(iter = i, alpha=alpha_seq,
                RMSE = sapply(alpha_seq, est_rmse, folds=folds_new))
  RMSE2 = bind_rows(RMSE2, rmse)
}

RMSE.mu = RMSE2 %>%
  group_by(alpha) %>% summarize(RMSE=mean(RMSE), RMSE.median = median(RMSE))

(alpha_hat = RMSE.mu %>% slice_min(RMSE) %>% pull(alpha) )


set.seed(535)
K = 10                
cv.fit = cv.glmnet(X.train, Y.train, nfolds=K, alpha=alpha_hat)
plot(cv.fit, las=1)

(lambda.hat = cv.fit$lambda.min)

coef(cv.fit, s = "lambda.min")
#Best alpha = 0
# Lambda = 0.002327301

```

## b. Fit a penalized *logistic regression* model to predict linkage.

Use an elastic net penalty (including lasso and ridge) (your choice).

-   Report the value of $\alpha \in [0, 1]$ used
-   Report the value of $\lambda$ used
-   Report the estimated coefficients

```{r }


set.seed(535)
K = 10                
cv_log.fit = cv.glmnet(X.train, Y.train, nfolds=K, alpha=alpha_hat, family = "binomial")
plot(cv_log.fit, las=1)

(lambda_log.hat = cv_log.fit$lambda.min)
coef(cv_log.fit, s = "lambda.min")

#Best alpha = 0
#Lambda = 0.002327301

```

## d. ROC curve: resampling estimate

Recreate the ROC curve from the penalized logistic regression model using repeated hold-out data. The following steps will guide you:

-   Fix $\alpha=.75$
-   Run the following steps 25 times:
    i.  Hold out 500 observations
    ii. Use the remaining observations to estimate $\lambda$ using 10-fold CV
    iii. Predict the probability of linkage for the 500 hold-out observations
    iv. Store the predictions and hold-out labels
-   Combine the results and produce the hold-out based ROC curve from all of the hold-out data. I'm looking for a single ROC curve using the predictions for all 12,500 (25 x 500) observations rather than 25 different curves.
-   Note: by estimating $\lambda$ each iteration, we are incorporating the uncertainty present in estimating that tuning parameter.

```{r }
library(yardstick)
set.seed(612)
alpha = 0.75
holdout = 500
K = 10 
yhat_log_reg = c()
yhat_labels = c()
true_labels = c()

for (i in 1:25) {
  test_ind = sample(nrow(X.train), size = holdout)
  train_ind = -test_ind
  
  cv_log_fit = cv.glmnet(x = X.train[train_ind, ], y = Y.train[train_ind], nfolds = K,alpha = alpha,family = "binomial")
  yhat_log_reg = c(yhat_log_reg, predict(cv_log_fit, newx = X.train[test_ind, ], s = "lambda.min", type = "response"))
  
  yhat_labels = c(yhat_labels, Y.train[test_ind])
  true_labels = c(true_labels, Y.train[test_ind])
}

roc_data =tibble(truth = factor(true_labels), estimate = yhat_log_reg)
roc_curve = roc_curve(roc_data, truth, estimate)

ggplot(roc_curve, aes(x = specificity, y = sensitivity)) +
  geom_line()
```

## e. Contest Part 1: Predict the estimated *probability* of linkage.

Predict the estimated *probability* of linkage for the test data (using any model).

-   Submit a .csv file (ensure comma separated format) named `lastname_firstname_1.csv` that includes the column named **p** that is your estimated posterior probability. We will use automated evaluation, so the format must be exact.
-   You are free to any model (even ones we haven't yet covered in the course).
-   You are free to use any data transformation or feature engineering.
-   You will receive credit for a proper submission; the top five scores will receive 2 bonus points.\
-   Your probabilities will be evaluated with respect to the mean negative Bernoulli log-likelihood (known as the average *log-loss* metric): $$ 
    L = - \frac{1}{M} \sum_{i=1}^m [y_i \log \, \hat{p}_i + (1 - y_i) \log \, (1 - \hat{p}_i)]
    $$ where $M$ is the number of test observations, $\hat{p}_i$ is the prediction for the $i$th test observation, and $y_i \in \{0,1\}$ are the true test set labels.

```{r }

library(FNN) # for knn.reg() function
library(tidymodels) 

K_knn = 173 #sqrt of 30,000
set.seed(10)

  
  knn_model = knn(train = X.train, test = X.test, cl = Y.train, k = K_knn, prob = TRUE)
  predicted_prob_knn = attr(knn_model, "prob")



estimated_probabilities = data.frame(p = predicted_prob_knn)


write.csv(estimated_probabilities, "~/School/Data Mining/Data/stammler_mark_1.csv")

```

## f. Contest Part 2: Predict the *linkage label*.

Predict the linkages for the test data (using any model).

-   Submit a .csv file (ensure comma separated format) named `lastname_firstname_2.csv` that includes the column named **linkage** that takes the value of 1 for linked pairs and 0 for unlinked pairs. We will use automated evaluation, so the format must be exact.
-   You are free to any model (even ones we haven't yet covered in the course).
-   You are free to use any data transformation or feature engineering.
-   Your labels will be evaluated based on total cost, where cost is equal to `1*FP + 8*FN`. This implies that False Negatives (FN) are 8 times as costly as False Positives (FP).\
-   You will receive credit for a proper submission; the top five scores will receive 2 bonus points. Note: you only will get bonus credit for one of the two contests.

```{r }

library(FNN)
library(tidymodels) 

K_knn = 173 #sqrt of 30,000
set.seed(13)



  knn_model_pred = FNN::knn(train = X.train, test = X.test, cl= Y.train ,k = K_knn)

write.csv(knn_model_pred, "~/School/Data Mining/Data/stammler_mark_2.csv")

```
